#!/usr/bin/env python
"""
æ‰¹é‡è¯„ä¼°æ‰€æœ‰ç”Ÿæˆçš„ completions.jsonl æ–‡ä»¶ï¼ˆç®€åŒ–ç‰ˆï¼‰
"""

import os
import subprocess
import glob
import json
import re
from datetime import datetime

# ================= é…ç½®åŒºåŸŸ =================
CONDA_ENV_PATH = "/scratch/yf3005/qwen-math"
EVAL_SCRIPT = "/home/yf3005/Qwen2.5-Math/evaluation/evaluate.py"
RESULTS_DIR = "/home/yf3005/search-and-learn/data/meta-llama/Llama-3.2-1B-Instruct"
OUTPUT_LOG = "/home/yf3005/search-and-learn/evaluation_results.txt"
OUTPUT_TSV = "/home/yf3005/search-and-learn/evaluation_summary.tsv"
# ===========================================

def get_jsonl_files(directory):
    """è·å–ç›®å½•ä¸‹æ‰€æœ‰çš„ completions.jsonl æ–‡ä»¶"""
    pattern = os.path.join(directory, "*_completions.jsonl")
    files = glob.glob(pattern)
    files.sort()
    return files

def extract_config_from_file(file_path):
    """ä»æ–‡ä»¶ç¬¬ä¸€è¡Œæå–é…ç½®ä¿¡æ¯"""
    try:
        with open(file_path, 'r') as f:
            first_line = f.readline().strip()
            if first_line.startswith('# CONFIG:'):
                config_json = first_line.replace('# CONFIG:', '').strip()
                config = json.loads(config_json)
                return config
    except Exception as e:
        print(f"   âš ï¸ æ— æ³•è¯»å–é…ç½®: {e}")
    return {}

def extract_generation_times_and_tokens(file_path):
    """ä»æ•°æ®æ–‡ä»¶ä¸­æå–ç”Ÿæˆæ—¶é—´ã€PRMè¯„åˆ†æ—¶é—´å’Œtokenç»Ÿè®¡"""
    llm_times = []
    prm_times = []
    total_times = []
    completion_tokens_list = []
    total_completions = 0
    estimated_tokens = 0
    
    try:
        with open(file_path, 'r') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                try:
                    data = json.loads(line)
                    # æå– llm_gen_time (æ–°æ ¼å¼ç›´æ¥æ˜¯æ•°å€¼)
                    if 'llm_gen_time' in data:
                        llm_time = data['llm_gen_time']
                        if isinstance(llm_time, list) and len(llm_time) > 0:
                            llm_times.append(llm_time[0])
                        elif isinstance(llm_time, (int, float)):
                            llm_times.append(llm_time)
                    
                    # æå– prm_score_time (æ–°æ ¼å¼ç›´æ¥æ˜¯æ•°å€¼)
                    if 'prm_score_time' in data:
                        prm_time = data['prm_score_time']
                        if isinstance(prm_time, list) and len(prm_time) > 0:
                            prm_times.append(prm_time[0])
                        elif isinstance(prm_time, (int, float)):
                            prm_times.append(prm_time)
                    
                    # æå– total_time_beam_search (æ–°æ ¼å¼å­—æ®µ)
                    if 'total_time_beam_search' in data:
                        total_time = data['total_time_beam_search']
                        if isinstance(total_time, (int, float)):
                            total_times.append(total_time)
                    
                    # ç»Ÿè®¡tokenä¿¡æ¯
                    if 'completion_tokens' in data:
                        tokens = data['completion_tokens']
                        if isinstance(tokens, list):
                            # å¦‚æœtokenséƒ½æ˜¯0ï¼Œä½¿ç”¨å­—ç¬¦é•¿åº¦ä¼°ç®— (çº¦4å­—ç¬¦=1token)
                            if all(t == 0 for t in tokens):
                                if 'completions' in data:
                                    completions = data['completions']
                                    total_completions += len(completions)
                                    # ä¼°ç®—tokens: å¹³å‡4ä¸ªå­—ç¬¦çº¦ç­‰äº1ä¸ªtoken
                                    estimated = sum(len(c) // 4 for c in completions)
                                    estimated_tokens += estimated
                                    completion_tokens_list.append(estimated)
                            else:
                                total_completions += len(tokens)
                                token_sum = sum(tokens)
                                estimated_tokens += token_sum
                                completion_tokens_list.append(token_sum)
                        elif isinstance(tokens, (int, float)):
                            completion_tokens_list.append(tokens)
                            estimated_tokens += tokens
                            total_completions += 1
                    elif 'completions' in data:
                        # å¦‚æœæ²¡æœ‰completion_tokenså­—æ®µï¼Œç›´æ¥ä»completionsä¼°ç®—
                        completions = data['completions']
                        total_completions += len(completions)
                        estimated = sum(len(c) // 4 for c in completions)
                        estimated_tokens += estimated
                        completion_tokens_list.append(estimated)
                        
                except json.JSONDecodeError:
                    continue
    except Exception as e:
        print(f"   âš ï¸ æ— æ³•è¯»å–æ—¶é—´ä¿¡æ¯: {e}")
    
    result = {}
    if llm_times:
        result['avg_llm_time'] = sum(llm_times) / len(llm_times)
        result['total_llm_time'] = sum(llm_times)
        result['num_samples'] = len(llm_times)
    
    if prm_times:
        result['avg_prm_time'] = sum(prm_times) / len(prm_times)
        result['total_prm_time'] = sum(prm_times)
    
    # ä¼˜å…ˆä½¿ç”¨ total_time_beam_searchï¼Œå¦‚æœæ²¡æœ‰åˆ™è®¡ç®—
    if total_times:
        result['avg_total_time'] = sum(total_times) / len(total_times)
        result['total_time'] = sum(total_times)
    elif llm_times and prm_times:
        result['avg_total_time'] = result['avg_llm_time'] + result['avg_prm_time']
        result['total_time'] = result['total_llm_time'] + result['total_prm_time']
    
    # æ·»åŠ tokenç»Ÿè®¡
    if completion_tokens_list:
        result['total_completions'] = total_completions
        result['total_tokens_estimated'] = estimated_tokens
        result['avg_tokens_per_sample'] = estimated_tokens / len(completion_tokens_list) if completion_tokens_list else 0
        result['avg_tokens_per_completion'] = estimated_tokens / total_completions if total_completions > 0 else 0
    
    return result if result else None

def extract_params_from_filename(filename):
    """ä»æ–‡ä»¶åæå–å‚æ•°"""
    params = {}
    
    # æå– n å€¼: beam_search_dynamic_n16_...
    n_match = re.search(r'_n(\d+)_', filename)
    if n_match:
        params['n'] = int(n_match.group(1))
    
    # æå– temperature: temp0.5 æˆ– temp0_5
    temp_match = re.search(r'_temp([0-9.]+)', filename)
    if temp_match:
        params['temperature'] = float(temp_match.group(1))
    
    # æå– strategy: cosine, exp ç­‰
    if '_cosine_' in filename:
        params['strategy'] = 'cosine'
    elif '_exp_' in filename:
        params['strategy'] = 'exp'
    elif '_linear_' in filename:
        params['strategy'] = 'linear'
    
    # æå–æ—¶é—´æˆ³: ..._20251206_030435_...
    timestamp_match = re.search(r'_(\d{8}_\d{6})_', filename)
    if timestamp_match:
        params['timestamp'] = timestamp_match.group(1)
    
    # æå– approach
    if 'beam_search_dynamic' in filename:
        params['approach'] = 'beam_search_dynamic'
    elif 'best_of_n' in filename:
        params['approach'] = 'best_of_n'
    elif 'beam_search' in filename:
        params['approach'] = 'beam_search'
    
    return params

def infer_params_from_sweep_order(n, timestamp, all_files):
    """æ ¹æ®æ‰«å‚é¡ºåºæ¨æ–­è¶…å‚æ•°
    
    æ‰«å‚é¡ºåº: product(N_VALUES, TEMP_VALUES, STRATEGY_VALUES)
    N_VALUES = [4, 16]
    TEMP_VALUES = [0.5, 0.8, 1.0, 2.0]
    STRATEGY_VALUES = ["exp", "cosine"]
    """
    TEMP_VALUES = [0.5, 0.8, 1.0, 2.0]
    STRATEGY_VALUES = ["exp", "cosine"]
    
    # è·å–ç›¸åŒ n å€¼çš„æ‰€æœ‰æ–‡ä»¶ï¼ŒæŒ‰æ—¶é—´æˆ³æ’åº
    same_n_files = [(f, extract_params_from_filename(os.path.basename(f))) 
                    for f in all_files 
                    if extract_params_from_filename(os.path.basename(f)).get('n') == n]
    same_n_files.sort(key=lambda x: x[1].get('timestamp', ''))
    
    # æ‰¾åˆ°å½“å‰æ–‡ä»¶åœ¨åˆ—è¡¨ä¸­çš„ç´¢å¼•
    current_idx = None
    for idx, (f, params) in enumerate(same_n_files):
        if params.get('timestamp') == timestamp:
            current_idx = idx
            break
    
    if current_idx is None:
        return None, None
    
    # æ ¹æ®ç´¢å¼•è®¡ç®—è¶…å‚æ•°
    # é¡ºåº: (n, temp, strategy) å…¶ä¸­ temp å’Œ strategy å¾ªç¯
    num_combinations = len(TEMP_VALUES) * len(STRATEGY_VALUES)
    
    if current_idx < num_combinations:
        temp_idx = current_idx // len(STRATEGY_VALUES)
        strategy_idx = current_idx % len(STRATEGY_VALUES)
        
        return TEMP_VALUES[temp_idx], STRATEGY_VALUES[strategy_idx]
    
    return None, None

def format_config_info(config, filename_params, all_files=None):
    """æ ¼å¼åŒ–é…ç½®ä¿¡æ¯ç”¨äºæ˜¾ç¤º"""
    info_lines = []
    
    # ä¼˜å…ˆä»æ–‡ä»¶åä¸­æå–å‚æ•°ï¼Œå› ä¸ºæ–°æ ¼å¼æ²¡æœ‰CONFIGæ³¨é‡Š
    n = filename_params.get('n') or config.get('n', 'N/A')
    temp = filename_params.get('temperature') or config.get('beam_decay_temperature') or config.get('temperature')
    strategy = filename_params.get('strategy') or config.get('beam_decay_strategy')
    approach = filename_params.get('approach') or config.get('approach', 'N/A')
    timestamp = filename_params.get('timestamp') or config.get('timestamp', 'N/A')
    
    # å¦‚æœé…ç½®ä¸­æ²¡æœ‰ temp å’Œ strategyï¼Œå°è¯•ä»æ‰«å‚é¡ºåºæ¨æ–­
    if (temp is None or strategy is None) and all_files and n != 'N/A' and timestamp != 'N/A':
        inferred_temp, inferred_strategy = infer_params_from_sweep_order(n, timestamp, all_files)
        if temp is None and inferred_temp is not None:
            temp = inferred_temp
        if strategy is None and inferred_strategy is not None:
            strategy = inferred_strategy
    
    if temp is None:
        temp = 'N/A'
    if strategy is None:
        strategy = 'N/A'
    
    info_lines.append(f"   Approach: {approach}")
    info_lines.append(f"   N: {n}")
    info_lines.append(f"   Temperature: {temp}")
    info_lines.append(f"   Strategy: {strategy}")
    info_lines.append(f"   Timestamp: {timestamp}")
    
    return '\n'.join(info_lines), {
        'approach': approach,
        'n': n,
        'temperature': temp,
        'strategy': strategy,
        'timestamp': timestamp
    }

def run_evaluation(file_path, output_file, all_files=None):
    """è¿è¡Œå•ä¸ªæ–‡ä»¶çš„è¯„ä¼°"""
    filename = os.path.basename(file_path)
    print(f"\n{'='*80}")
    print(f"ğŸ“Š æ­£åœ¨è¯„ä¼°: {filename}")
    print(f"{'='*80}")
    
    # æå–é…ç½®ä¿¡æ¯
    config = extract_config_from_file(file_path)
    filename_params = extract_params_from_filename(filename)
    config_info, params_dict = format_config_info(config, filename_params, all_files)
    
    # æå–ç”Ÿæˆæ—¶é—´å’Œtokenç»Ÿè®¡
    time_info = extract_generation_times_and_tokens(file_path)
    print(config_info)
    if time_info:
        if 'avg_llm_time' in time_info:
            print(f"   Avg LLM Time: {time_info['avg_llm_time']:.2f}s")
            params_dict['avg_llm_time'] = round(time_info['avg_llm_time'], 2)
            params_dict['total_llm_time'] = round(time_info['total_llm_time'], 2)
        
        if 'avg_prm_time' in time_info:
            print(f"   Avg PRM Time: {time_info['avg_prm_time']:.2f}s")
            params_dict['avg_prm_time'] = round(time_info['avg_prm_time'], 2)
            params_dict['total_prm_time'] = round(time_info['total_prm_time'], 2)
        
        if 'avg_total_time' in time_info:
            print(f"   Avg Total Time: {time_info['avg_total_time']:.2f}s")
            params_dict['avg_total_time'] = round(time_info['avg_total_time'], 2)
            params_dict['total_time'] = round(time_info['total_time'], 2)
        
        if 'num_samples' in time_info:
            print(f"   Num Samples: {time_info['num_samples']}")
            params_dict['num_samples'] = time_info['num_samples']
        
        # æ·»åŠ tokenç»Ÿè®¡ä¿¡æ¯
        if 'total_tokens_estimated' in time_info:
            print(f"   Total Tokens (est): {time_info['total_tokens_estimated']:,}")
            print(f"   Avg Tokens/Sample: {time_info['avg_tokens_per_sample']:.1f}")
            print(f"   Avg Tokens/Completion: {time_info['avg_tokens_per_completion']:.1f}")
            print(f"   Total Completions: {time_info['total_completions']}")
            params_dict['total_tokens_estimated'] = time_info['total_tokens_estimated']
            params_dict['avg_tokens_per_sample'] = round(time_info['avg_tokens_per_sample'], 1)
            params_dict['avg_tokens_per_completion'] = round(time_info['avg_tokens_per_completion'], 1)
            params_dict['total_completions'] = time_info['total_completions']
    
    # ç›´æ¥ä½¿ç”¨ conda ç¯å¢ƒä¸­çš„ python
    python_path = os.path.join(CONDA_ENV_PATH, "bin", "python")
    
    cmd = [
        python_path,
        EVAL_SCRIPT,
        "--file_path",
        file_path
    ]
    
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            check=True,
            timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
        )
        
        # æå–å‡†ç¡®ç‡
        accuracy = None
        output = result.stdout
        
        # å°è¯•å¤šç§æ ¼å¼æå–å‡†ç¡®ç‡
        # æ ¼å¼1: 'acc': 56.0
        match = re.search(r"'acc'\s*:\s*(\d+\.?\d*)", output)
        if match:
            accuracy = float(match.group(1))
        else:
            # æ ¼å¼2: accuracy: 56.0% æˆ– accuracy: 56.0
            for line in output.split('\n'):
                if 'accuracy' in line.lower() or 'acc' in line.lower():
                    # å°è¯•æå–ç™¾åˆ†æ¯”
                    match = re.search(r'(\d+\.?\d*)\s*%', line)
                    if match:
                        accuracy = float(match.group(1))
                        break
                    # å°è¯•æå–æ•°å­—
                    match = re.search(r':\s*(\d+\.?\d*)', line)
                    if match:
                        accuracy = float(match.group(1))
                        break
        
        # å†™å…¥æ—¥å¿—
        with open(output_file, 'a') as f:
            f.write(f"\n{'='*80}\n")
            f.write(f"æ–‡ä»¶: {filename}\n")
            f.write(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"{'='*80}\n")
            f.write(config_info + "\n")
            f.write(f"{'='*80}\n")
            f.write(result.stdout)
            if result.stderr:
                f.write(f"\n--- STDERR ---\n{result.stderr}\n")
            f.write("\n")
        
        print(f"âœ… å®Œæˆ: {filename}")
        
        # æ‰“å°å‡†ç¡®ç‡
        if accuracy is not None:
            print(f"   ğŸ“ˆ Accuracy: {accuracy}%")
            params_dict['accuracy'] = accuracy
        else:
            print(f"   âš ï¸ æœªèƒ½æå–å‡†ç¡®ç‡")
            for line in result.stdout.split('\n'):
                if 'accuracy' in line.lower() or 'correct' in line.lower():
                    print(f"   {line.strip()}")
        
        return True, params_dict
        
    except subprocess.TimeoutExpired:
        error_msg = f"âŒ è¶…æ—¶: {filename}"
        print(error_msg)
        with open(output_file, 'a') as f:
            f.write(f"\n{'='*80}\n")
            f.write(f"æ–‡ä»¶: {filename}\n")
            f.write(f"{'='*80}\n")
            f.write(f"{error_msg}\n\n")
        return False, {}
        
    except subprocess.CalledProcessError as e:
        error_msg = f"âŒ å¤±è´¥: {filename}\né”™è¯¯: {e}"
        print(error_msg)
        if e.stderr:
            print(f"   {e.stderr[:200]}")
        
        with open(output_file, 'a') as f:
            f.write(f"\n{'='*80}\n")
            f.write(f"æ–‡ä»¶: {filename}\n")
            f.write(f"{'='*80}\n")
            f.write(f"âŒ è¯„ä¼°å¤±è´¥\n{error_msg}\n")
            if e.stderr:
                f.write(f"STDERR:\n{e.stderr}\n")
            f.write("\n")
        return False, {}

def main():
    # æ¸…ç©ºæˆ–åˆ›å»ºè¾“å‡ºæ—¥å¿—æ–‡ä»¶
    with open(OUTPUT_LOG, 'w') as f:
        f.write(f"æ‰¹é‡è¯„ä¼°ç»“æœ\n")
        f.write(f"ç»“æœç›®å½•: {RESULTS_DIR}\n")
        f.write(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"{'='*80}\n\n")
    
    # è·å–æ‰€æœ‰æ–‡ä»¶
    jsonl_files = get_jsonl_files(RESULTS_DIR)
    
    if not jsonl_files:
        print(f"âŒ åœ¨ {RESULTS_DIR} ä¸­æœªæ‰¾åˆ°ä»»ä½• completions.jsonl æ–‡ä»¶")
        return
    
    print(f"ğŸš€ æ‰¾åˆ° {len(jsonl_files)} ä¸ªæ–‡ä»¶å¾…è¯„ä¼°")
    print(f"ğŸ“‚ ç»“æœç›®å½•: {RESULTS_DIR}")
    print(f"ğŸ“ æ—¥å¿—è¾“å‡º: {OUTPUT_LOG}")
    print(f"ğŸ“Š TSVæ±‡æ€»: {OUTPUT_TSV}")
    print(f"ğŸ Python: {CONDA_ENV_PATH}/bin/python\n")
    
    # ç»Ÿè®¡
    success_count = 0
    failed_count = 0
    results = []
    
    # é€ä¸ªè¯„ä¼°
    for idx, file_path in enumerate(jsonl_files, 1):
        print(f"\nè¿›åº¦: [{idx}/{len(jsonl_files)}]")
        
        success, params = run_evaluation(file_path, OUTPUT_LOG, jsonl_files)
        if success:
            success_count += 1
            if params:
                params['filename'] = os.path.basename(file_path)
                results.append(params)
        else:
            failed_count += 1
    
    # ç”Ÿæˆ TSV æ±‡æ€»è¡¨
    if results:
        import csv
        with open(OUTPUT_TSV, 'w', newline='') as f:
            fieldnames = ['filename', 'approach', 'n', 'temperature', 'strategy', 'timestamp', 'accuracy', 
                         'avg_llm_time', 'avg_prm_time', 'avg_total_time', 
                         'total_llm_time', 'total_prm_time', 'total_time', 'num_samples']
            writer = csv.DictWriter(f, fieldnames=fieldnames, delimiter='\t')
            writer.writeheader()
            for result in results:
                writer.writerow(result)
        
        print(f"\nğŸ“Š TSVæ±‡æ€»è¡¨å·²ç”Ÿæˆ: {OUTPUT_TSV}")
        
        # æŒ‰è¶…å‚æ•°åˆ†ç»„æ˜¾ç¤ºç»“æœ
        print(f"\n{'='*80}")
        print(f"ğŸ“ˆ ç»“æœæ±‡æ€»ï¼ˆæŒ‰è¶…å‚æ•°åˆ†ç»„ï¼‰")
        print(f"{'='*80}")
        
        # æŒ‰ n, temperature, strategy åˆ†ç»„
        grouped = {}
        for r in results:
            key = (r.get('n'), r.get('temperature'), r.get('strategy'))
            if key not in grouped:
                grouped[key] = []
            grouped[key].append(r)
        
        for key, items in sorted(grouped.items()):
            n, temp, strategy = key
            print(f"\nN={n}, Temperature={temp}, Strategy={strategy}")
            for item in items:
                acc = item.get('accuracy', 'N/A')
                ts = item.get('timestamp', 'N/A')
                avg_total = item.get('avg_total_time', item.get('avg_llm_time', 'N/A'))
                avg_llm = item.get('avg_llm_time', 'N/A')
                avg_prm = item.get('avg_prm_time', 'N/A')
                print(f"  - {ts}: Accuracy={acc}%, LLM={avg_llm}s, PRM={avg_prm}s, Total={avg_total}s")
    
    # æ€»ç»“
    print(f"\n{'='*80}")
    print(f"ğŸ‰ è¯„ä¼°å®Œæˆï¼")
    print(f"{'='*80}")
    print(f"âœ… æˆåŠŸ: {success_count}")
    print(f"âŒ å¤±è´¥: {failed_count}")
    print(f"ğŸ“Š æ€»è®¡: {len(jsonl_files)}")
    print(f"ğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {OUTPUT_LOG}")
    print(f"ğŸ“Š TSVæ±‡æ€»å·²ä¿å­˜åˆ°: {OUTPUT_TSV}")
    
    # å†™å…¥æ€»ç»“
    with open(OUTPUT_LOG, 'a') as f:
        f.write(f"\n{'='*80}\n")
        f.write(f"è¯„ä¼°æ€»ç»“\n")
        f.write(f"{'='*80}\n")
        f.write(f"æˆåŠŸ: {success_count}\n")
        f.write(f"å¤±è´¥: {failed_count}\n")
        f.write(f"æ€»è®¡: {len(jsonl_files)}\n")
        f.write(f"ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

if __name__ == "__main__":
    main()
