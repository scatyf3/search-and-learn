# Speculative decoding config for best_of_n

model_path: meta-llama/Llama-3.2-3B-Instruct
approach: best_of_n_speculative
n: 4
sort_completed: true
filter_duplicates: true
draft_model_path: meta-llama/Llama-3.2-1B-Instruct
seed: 0
llm_backend: transformers
prm_batch_size: 4