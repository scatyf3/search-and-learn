import time
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

checkpoint = "facebook/layerskip-llama3.2-1B"
device = "cuda" if torch.cuda.is_available() else "cpu"

tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)

# ã€å…³é”®çº¦æŸã€‘å®˜æ–¹çš„ assistant_early_exit ç›®å‰ä¸æ”¯æŒ Batchingï¼Œå¿…é¡»å•æ¡è·‘
prompt = "Alice and Bob are playing a game of"
inputs = tokenizer(prompt, return_tensors="pt").to(device)

# åŸºç¡€å‚æ•°
common_kwargs = {
    "do_sample": False,
    "max_new_tokens": 60, # ç¨å¾®é•¿ä¸€ç‚¹ï¼Œä½“ç°æŠ•æœºä¼˜åŠ¿
    "pad_token_id": tokenizer.eos_token_id,
}

print("-" * 60)
print(f"Device: {device}")
print("Mode: Speculative Decoding within single model (Self-Speculation)")
print("-" * 60)

# --- 1. åŸºå‡†ï¼šå®Œæ•´æ¨¡å‹ (Baseline) ---
print(">>> Running Standard Full Model...")
# é¢„çƒ­
model.generate(**inputs, max_new_tokens=2)
torch.cuda.synchronize()

start = time.perf_counter()
output_base = model.generate(**inputs, **common_kwargs)
torch.cuda.synchronize()
time_base = time.perf_counter() - start

# --- 2. å®˜æ–¹å‚æ•°ï¼šassistant_early_exit ---
EXIT_LAYER = 4
NUM_SPECULATIVE_TOKENS = 5  # ã€æ ¸å¿ƒå‚æ•°ã€‘æ¯æ¬¡æŠ•æœº 5 ä¸ª Token

print(f">>> Running with assistant_early_exit={EXIT_LAYER} (K={NUM_SPECULATIVE_TOKENS})...")

# é¢„çƒ­
model.generate(
    **inputs, 
    max_new_tokens=2, 
    assistant_early_exit=EXIT_LAYER, 
    num_assistant_tokens=NUM_SPECULATIVE_TOKENS
)
torch.cuda.synchronize()

start = time.perf_counter()

# ğŸ”¥ è¿™é‡Œå°±æ˜¯ä½ è¦çš„å®˜æ–¹ç”¨æ³•
output_spec = model.generate(
    **inputs, 
    **common_kwargs,
    # å‘Šè¯‰æ¨¡å‹ï¼šç”¨ç¬¬4å±‚å½“è‰ç¨¿
    assistant_early_exit=EXIT_LAYER, 
    # å‘Šè¯‰æ¨¡å‹ï¼šæ¯æ¬¡è‰ç¨¿ç”Ÿæˆ 5 ä¸ªï¼Œç„¶åè®© 16 å±‚ä¸€æ¬¡æ€§éªŒè¯
    num_assistant_tokens=NUM_SPECULATIVE_TOKENS 
)
torch.cuda.synchronize()
time_spec = time.perf_counter() - start

# --- ç»“æœå¯¹æ¯” ---
print("-" * 60)
print(f"Standard Time: {time_base:.4f}s")
print(f"LayerSkip Time: {time_spec:.4f}s")
speedup = time_base / time_spec
print(f"ğŸš€ Speedup: {speedup:.2f}x")

# éªŒè¯å†…å®¹
text_base = tokenizer.decode(output_base[0], skip_special_tokens=True)
text_spec = tokenizer.decode(output_spec[0], skip_special_tokens=True)

print("-" * 60)
if text_base == text_spec:
    print("âœ… å†…å®¹å®Œå…¨ä¸€è‡´ (æŠ•æœºé‡‡æ ·éªŒè¯æˆåŠŸ)")
else:
    print("âŒ å†…å®¹ä¸ä¸€è‡´ (é€»è¾‘å¼‚å¸¸)")

print(f"Text: {text_spec[:100]}...")